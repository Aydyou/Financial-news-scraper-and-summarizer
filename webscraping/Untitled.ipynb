{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import re\n",
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "### This part is only for yahoo finance\n",
    "url=(\"https://finance.yahoo.com/rss/industry?\")\n",
    "r1=requests.get(url)\n",
    "coverpage = str(r1.content)\n",
    "\n",
    "\n",
    "yahoolinks=re.findall(\"<link>(.*?)</link>\", coverpage)\n",
    "\n",
    "yahootext = re.findall(\"&gt(.*?)&lt\", coverpage)\n",
    "yahootext=yahootext[15:]\n",
    "for i in yahootext:\n",
    "    if i.startswith(\";<\"):\n",
    "        yahootext.remove(i)\n",
    "        \n",
    "for i in yahootext:\n",
    "    if i==\";\":\n",
    "        yahootext.remove(i)\n",
    "yahootext=list(set(yahootext))\n",
    "\n",
    "\n",
    "### This part is for nytimes\n",
    "\n",
    "links=[\"https://rss.nytimes.com/services/xml/rss/nyt/Business.xml\", \"https://rss.nytimes.com/services/xml/rss/nyt/Economy.xml\"]\n",
    "ny=\"\"\n",
    "for url in links:\n",
    "    r2 = requests.get(url)\n",
    "    ny+=r2.text\n",
    "\n",
    "\n",
    "nylinks=re.findall(\"<link>(.*?)</link>\", ny)\n",
    "nylinks=nylinks[2:]\n",
    "nytext=[]\n",
    "\n",
    "nylinks=list(set(nylinks))\n",
    "\n",
    "\n",
    "headers={\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/70.0.3538.102 Safari/537.36 Edge/18.18362\"}\n",
    "\n",
    "for url in nylinks:\n",
    "    \n",
    "    session = requests.Session()\n",
    "    session.auth = (\"XXXXX\", \"XXXXX\")\n",
    "\n",
    "    auth = session.post(\"https://www.nytimes.com/\")\n",
    "    r3=session.get(url,headers=headers)\n",
    "    temp=re.findall(\"<p class=\\\"css-158dogj evys1bk0\\\">(.*?)</p>\", r3.text)  \n",
    "    temp=temp[1:]\n",
    "    string=\"\"\n",
    "    for i in temp:\n",
    "        string+=i\n",
    "    string.join(\"/n\")\n",
    "    nytext.append(string)\n",
    "\n",
    "nytext=list(set(nytext))\n",
    "\n",
    "### This section is for forbes\n",
    "\n",
    "source = urlopen('https://www.forbes.com/markets')\n",
    "soup = BeautifulSoup(source,'lxml')\n",
    "\n",
    "lstforbesmarket = []\n",
    "for i in soup.findAll('a', {'class': \"section-pick__title\" }):\n",
    "    title = i.text\n",
    "    link = i['href']\n",
    "    lstforbesmarket.append(link)\n",
    "\n",
    "forbestext=[]\n",
    "\n",
    "for url in lstforbesmarket:\n",
    "\n",
    "    \n",
    "    r4=requests.get(url,headers=headers)\n",
    "\n",
    "    temp=re.findall(\"<p>(.*?)</p>\", r4.text)\n",
    "    temp=temp[2:]\n",
    "\n",
    "    \n",
    "    string=\"\"\n",
    "    for i in temp:\n",
    "        string+=i\n",
    "    string.join(\"/n\")\n",
    "    forbestext.append(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from transformers import pipeline, AutoModelForTokenClassification, AutoTokenizer\n",
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer as SIA\n",
    "\n",
    "\n",
    "summarizer = pipeline(\"summarization\", framework=\"pt\", device=0)\n",
    "\n",
    "\n",
    "### helper function for dividing the text to smaller size so that it could be fed into the model\n",
    "def chunkstring(string, length):\n",
    "    return (string[0+i:length+i] for i in range(0, len(string), length))\n",
    "\n",
    "yahoo=\"\"\n",
    "ny=\"\"\n",
    "forbes=\"\"\n",
    "\n",
    "for i in yahootext:\n",
    "    yahoo+=(\" \"+i)\n",
    "for i in nytext:\n",
    "    ny+=(\" \"+i)\n",
    "for i in forbestext:\n",
    "    forbes+=(\" \"+i)\n",
    "### This is all the text that needs to be summarized\n",
    "text=yahoo+\" \"+ny+\" \"+forbes\n",
    "\n",
    "### We chunk the text into smaller parts\n",
    "chunkedstring=list(chunkstring(text, 1024))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, request, render_template\n",
    "\n",
    "\n",
    "\n",
    "url = 'http://localhost:3000/predict'\n",
    "\n",
    "app = Flask(__name__, template_folder=\"templates\")\n",
    "\n",
    "# Load the model\n",
    "\n",
    "@app.route('/', methods=['GET','POST'])\n",
    "\n",
    "\n",
    "def home():\n",
    "    \n",
    "    global sentimentscore\n",
    "    global answer\n",
    "    global counter\n",
    "    ### With each click we take batches of size 20 from the chunkedstring and pass it through the summarization pipeline\n",
    "    ### and give it a sentiment score. Vader sentiment score is between -1 and 1 so we scale it to be between 0 and 100. \n",
    "    ### Witch each click the sentiment score is averaged over all the previous clicks.\n",
    "    if request.method == 'POST':\n",
    "        batch=20\n",
    "        \n",
    "        for i in range(0,batch):\n",
    "            temp=summarizer(chunkedstring[counter+i], min_length=0, max_length=20)[0]['summary_text']\n",
    "            score=SIA().polarity_scores(chunkedstring[counter+i])[\"compound\"]\n",
    "            sentimentscore.append(score)\n",
    "            answer.append(temp)\n",
    "        counter+=20\n",
    "        return render_template('demo.html', sentiment= answer[counter-20]+\". \" +\"The sentiment score so far is \"+ str(int(50*(1+np.mean(sentimentscore[:counter-19])))),\n",
    "                                  sentiment2= answer[counter-19]+\". \" +\"The sentiment score so far is \"+ str(int(50*(1+np.mean(sentimentscore[:counter-18])))),\n",
    "                              sentiment3= answer[counter-18]+\". \" +\"The sentiment score so far is \"+ str(int(50*(1+np.mean(sentimentscore[:counter-17])))),\n",
    "                              sentiment4= answer[counter-17]+\". \" +\"The sentiment score so far is \"+ str(int(50*(1+np.mean(sentimentscore[:counter-16])))),\n",
    "                              sentiment5= answer[counter-16]+\". \" +\"The sentiment score so far is \"+ str(int(50*(1+np.mean(sentimentscore[:counter-15])))),\n",
    "                              sentiment6= answer[counter-15]+\". \" +\"The sentiment score so far is \"+ str(int(50*(1+np.mean(sentimentscore[:counter-14])))),\n",
    "                              sentiment7= answer[counter-14]+\". \" +\"The sentiment score so far is \"+ str(int(50*(1+np.mean(sentimentscore[:counter-13])))),\n",
    "                              sentiment8= answer[counter-13]+\". \" +\"The sentiment score so far is \"+ str(int(50*(1+np.mean(sentimentscore[:counter-12])))),\n",
    "                              sentiment9= answer[counter-12]+\". \" +\"The sentiment score so far is \"+ str(int(50*(1+np.mean(sentimentscore[:counter-11])))),\n",
    "                              sentiment10= answer[counter-11]+\". \" +\"The sentiment score so far is \"+ str(int(50*(1+np.mean(sentimentscore[:counter-10])))),\n",
    "                              sentiment11= answer[counter-10]+\". \" +\"The sentiment score so far is \"+ str(int(50*(1+np.mean(sentimentscore[:counter-9])))),\n",
    "                              sentiment12= answer[counter-9]+\". \" +\"The sentiment score so far is \"+ str(int(50*(1+np.mean(sentimentscore[:counter-8])))),\n",
    "                              sentiment13= answer[counter-8]+\". \" +\"The sentiment score so far is \"+ str(int(50*(1+np.mean(sentimentscore[:counter-7])))),\n",
    "                              sentiment14= answer[counter-7]+\". \" +\"The sentiment score so far is \"+ str(int(50*(1+np.mean(sentimentscore[:counter-6])))),\n",
    "                              sentiment15= answer[counter-6]+\". \" +\"The sentiment score so far is \"+ str(int(50*(1+np.mean(sentimentscore[:counter-5])))),\n",
    "                              sentiment16= answer[counter-5]+\". \" +\"The sentiment score so far is \"+ str(int(50*(1+np.mean(sentimentscore[:counter-4])))),\n",
    "                              sentiment17= answer[counter-4]+\". \" +\"The sentiment score so far is \"+ str(int(50*(1+np.mean(sentimentscore[:counter-3])))),\n",
    "                              sentiment18= answer[counter-3]+\". \" +\"The sentiment score so far is \"+ str(int(50*(1+np.mean(sentimentscore[:counter-2])))),\n",
    "                              sentiment19= answer[counter-2]+\". \" +\"The sentiment score so far is \"+ str(int(50*(1+np.mean(sentimentscore[:counter-1])))),\n",
    "                              sentiment20= answer[counter-1]+\". \" +\"The sentiment score so far is \"+ str(int(50*(1+np.mean(sentimentscore[:counter])))))\n",
    "        \n",
    "\n",
    "        \n",
    "        \n",
    "    return render_template('demo.html', sentiment='', sentiment2='', sentiment3='', sentiment4='', sentiment5='', sentiment6='', sentiment7='',\n",
    "                           sentiment8='', sentiment9='', sentiment10='', sentiment11='', sentiment12='', sentiment13='', sentiment14='', \n",
    "                           sentiment15='', sentiment16='', sentiment17='', sentiment18='', sentiment19='', sentiment20='')\n",
    "        \n",
    "        \n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    app.run(port=3000, debug=False)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
